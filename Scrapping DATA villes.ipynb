{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class':'company'})\n",
    "    if len(company) > 0:\n",
    "        for b in company:\n",
    "            companies.append(b.text.strip())\n",
    "    else:\n",
    "        sec_try = div.find_all(name='span', attrs={'class':'result-link-source'})\n",
    "        for span in sec_try:\n",
    "            companies.append(span.text.strip())\n",
    "    return(companies)\n",
    " \n",
    "# extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'location'})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "# extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_from_result(soup): \n",
    "    salaries = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        try:\n",
    "            salaries.append(div.find('nobr').text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name='div', attrs={'class':'sjcl'})\n",
    "                div_three = div_two.find('div')\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append('Nothing_found')\n",
    "    return(salaries)\n",
    "\n",
    "# extract_salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'summary'})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return(summaries)\n",
    "\n",
    "# extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 3000 # Not necessary to put a very high value, 3000 is more than enough\n",
    "\n",
    "city_set = ['Paris', 'Marseille', 'Toulouse', 'Lyon', 'Bordeaux', 'Nice', 'Strasbourg', 'Lille', 'Nantes','Nancy'] #Cities you want to scrap for offers\n",
    "\n",
    "cols = ['city', 'location', 'job_title', 'company_name', 'summary', 'date', 'salary'] #Columns creation for future dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assembling the entire webscraping process\n",
    "job_post_title = []\n",
    "job_post_company = []\n",
    "job_post_location = []\n",
    "job_post_summary = []\n",
    "job_post_date = []\n",
    "job_post_salary = []\n",
    "job_post_city = []\n",
    "\n",
    "for city in city_set:\n",
    "    \n",
    "    \n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "\n",
    "        page = requests.get('http://www.indeed.fr/emplois?q=data&l=' + str(city) + '&start=' + str(start))\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(page.text, \"lxml\")\n",
    "        \n",
    "\n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "            \n",
    "            \n",
    "            job_post_city.append(city)\n",
    "            \n",
    "            #LOCATION\n",
    "  \n",
    "            location = div.find(name='span', attrs={'class': 'location accessible-contrast-color-location'})\n",
    "\n",
    "            if location:\n",
    "                job_post_location.append(location.text)\n",
    "            else:\n",
    "                job_post_location.append(\"NAN\")\n",
    "            \n",
    "            #TITLE\n",
    "\n",
    "            title = div.find(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"})\n",
    "\n",
    "            if title == None :\n",
    "                job_post_title.append(\"Nan\")\n",
    "            else :\n",
    "                job_post_title.append(title.text)\n",
    "\n",
    "            #COMPANY\n",
    "\n",
    "            company = div.find(name=\"span\", attrs={\"class\":\"company\"})\n",
    "\n",
    "            if company == None :\n",
    "                job_post_company.append(\"Nan\")\n",
    "            else :\n",
    "                job_post_company.append(company.text.strip())\n",
    "\n",
    "\n",
    "            #SUMMARY\n",
    "\n",
    "            summary = div.find(name=\"div\", attrs={\"class\":\"summary\"})\n",
    "\n",
    "            if summary == None :\n",
    "                job_post_summary.append(\"Nan\")\n",
    "            else :\n",
    "                job_post_summary.append(summary.text)\n",
    "\n",
    "            #DATE\n",
    "\n",
    "            date = div.find(name=\"span\", attrs={\"class\":\"date\"})\n",
    "\n",
    "            if date == None :\n",
    "                job_post_date.append(\"Nan\")\n",
    "            else :\n",
    "                job_post_date.append(date.text)\n",
    "\n",
    "            #SALARY\n",
    "\n",
    "            salary = div.find(name=\"span\", attrs={\"class\":\"salaryText\"})\n",
    "\n",
    "            if salary == None :\n",
    "                job_post_salary.append(\"Nan\")\n",
    "            else :\n",
    "                job_post_salary.append(salary.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling dataframe\n",
    "df = pd.DataFrame()    \n",
    "df['city'] = job_post_city\n",
    "df['location'] = job_post_location\n",
    "df['title'] = job_post_title\n",
    "df['company_name'] = job_post_company\n",
    "df['summary'] = job_post_summary\n",
    "df['date'] = job_post_date\n",
    "df['salary'] = job_post_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54798, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('DATA_offer_city.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
