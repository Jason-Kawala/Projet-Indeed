{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import warnings\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "warnings.simplefilter(action='ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "stemmer = FrenchStemmer()\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "stop_fr = nltk.corpus.stopwords.words('french')\n",
    "stop_uk = nltk.corpus.stopwords.words('english')\n",
    "stop_spacy_fr = list(fr_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DATA_FULL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].str.replace(',','.')\n",
    "df.Rating = df.Rating.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    import unidecode\n",
    "    text = tokenizer.tokenize(text.lower())\n",
    "    text = [word for word in text if not word in stop_fr]\n",
    "    text = [word for word in text if not word in stop_uk]\n",
    "    text = [word for word in text if not word in stop_spacy_fr]\n",
    "    text = [word for word in text if not word in ['euse']]\n",
    "    text = [stemmer.stem(word) for word in text]\n",
    "    text = [re.sub(\"\\d+\", \"\", word) for word in text]\n",
    "    text = [unidecode.unidecode(word) for word in text]\n",
    "    # get unique locations\n",
    "    uniqueLocation=list(df.Location.unique())\n",
    "    uniqueLocation=[x.lower() for x in uniqueLocation]\n",
    "    text = [word for word in text if not any(word in s for s in uniqueLocation)]\n",
    "    return text\n",
    "\n",
    "def concatExtractedWords(title,summary):\n",
    "    concatWords=parse_text(title)+parse_text(summary)\n",
    "    return concatWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BagOfWords'] = df.apply(lambda x: concatExtractedWords(x.Title, x.Description), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BagOfWords'] = df['BagOfWords'].apply(lambda x: ','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(doc):\n",
    "    \"\"\"\n",
    "    Input  : cleaned documents\n",
    "    Purpose: create term dictionary of corpus and convert it into Document Term Matrix\n",
    "    Output : term dictionary and Document Term Matrix\n",
    "    \"\"\"\n",
    "    # create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "    cvna = CountVectorizer(tokenizer=parse_text, ngram_range=(\n",
    "        1, 3), stop_words=stop_fr, strip_accents='ascii', max_df=.8)\n",
    "    data_cvna = cvna.fit_transform(doc)\n",
    "    data_dtmna = pd.DataFrame(\n",
    "        data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "    \n",
    "    # create the term_document matrix\n",
    "    doc_term_matrix = matutils.Sparse2Corpus(\n",
    "        scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "    \n",
    "    # create the vocabulary dictionary\n",
    "    dictionary = dict((v, k) for k, v in cvna.vocabulary_.items())\n",
    "\n",
    "    return dictionary, doc_term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA features\n",
    "\n",
    "Using dimensionality reduction techniques to get the most important topics of the corpus via LSA / LDA and NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that we have the term_document matrix we can run the lsa\n",
    "\n",
    "import re\n",
    "def create_gensim_lsa_model(docs, number_of_topics, chunk=2000):\n",
    "    \"\"\"\n",
    "    Input  : cleaned documents, number of topics and number of chunk per topic\n",
    "    Purpose: create LSA model using gensim\n",
    "    Output : return LSA model\n",
    "    \"\"\"\n",
    "    dictionary, doc_term_matrix = prepare_corpus(docs)\n",
    "    \n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics,\n",
    "                        id2word=dictionary, chunksize=chunk)\n",
    "    \n",
    "    return lsamodel, doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics=5\n",
    "lsa, doc_term_matrix=create_gensim_lsa_model(df['Title'],number_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at which topics each row contains\n",
    "corpus_transformed = lsa[doc_term_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the result into numpy array to get the score for each title \n",
    "all_topics_csr = matutils.corpus2csc(corpus_transformed)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsa1</th>\n",
       "      <th>lsa2</th>\n",
       "      <th>lsa3</th>\n",
       "      <th>lsa4</th>\n",
       "      <th>lsa5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046282</td>\n",
       "      <td>0.027923</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.019654</td>\n",
       "      <td>0.323825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843184</td>\n",
       "      <td>-0.155558</td>\n",
       "      <td>0.341612</td>\n",
       "      <td>-0.091903</td>\n",
       "      <td>-0.182890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lsa1      lsa2      lsa3      lsa4      lsa5\n",
       "0  0.046282  0.027923  0.079400  0.019654  0.323825\n",
       "1  0.843184 -0.155558  0.341612 -0.091903 -0.182890"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lsa_Topic = pd.DataFrame(all_topics_numpy, index=df.index, columns=[\n",
    "                         'lsa1', 'lsa2', 'lsa3', 'lsa4', 'lsa5'])\n",
    "Lsa_Topic.head(2)\n",
    "# our brand new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gensim_lda_model(docs, number_of_topics, passe=20, iters=100, chunk=2000):\n",
    "    \"\"\"\n",
    "    Input  : clean document, number of topics and number of iteration, chunks, passes to use \n",
    "    Purpose: create LSA model using gensim\n",
    "    Output : return LSA model\n",
    "    \"\"\"\n",
    "    dictionary, doc_term_matrix = prepare_corpus(docs)\n",
    "    # generate LDA model\n",
    "    ldamodel = models.LdaModel(corpus=doc_term_matrix, id2word=dictionary, num_topics=number_of_topics,\n",
    "                               iterations=iters, passes=passe, chunksize=chunk, random_state=1)\n",
    "    \n",
    "    return ldamodel, doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*\"projet\" + 0.019*\"chef\" + 0.019*\"chef projet\" + 0.016*\"analyst\" + 0.013*\"stag\" + 0.012*\"ingenieur\" + 0.011*\"business\" + 0.011*\"dat\" + 0.010*\"developp\" + 0.009*\"consult\"'),\n",
       " (1,\n",
       "  '0.037*\"architect\" + 0.029*\"dat\" + 0.012*\"devop\" + 0.011*\"manag\" + 0.011*\"consult\" + 0.008*\"solut\" + 0.007*\"expert\" + 0.007*\"lead\" + 0.006*\"freelanc\" + 0.006*\"scienc\"'),\n",
       " (2,\n",
       "  '0.039*\"dat\" + 0.023*\"scientist\" + 0.022*\"dat scientist\" + 0.020*\"consult\" + 0.017*\"developpeur\" + 0.017*\"engine\" + 0.014*\"end\" + 0.013*\"manag\" + 0.010*\"senior\" + 0.008*\"learning\"'),\n",
       " (3,\n",
       "  '0.059*\"dat\" + 0.050*\"ingenieur\" + 0.047*\"engine\" + 0.034*\"devop\" + 0.023*\"dat engine\" + 0.017*\"analyst\" + 0.014*\"consult\" + 0.013*\"dat analyst\" + 0.013*\"senior\" + 0.012*\"softwar\"'),\n",
       " (4,\n",
       "  '0.065*\"developpeur\" + 0.020*\"web\" + 0.015*\"full\" + 0.015*\"stack\" + 0.015*\"full stack\" + 0.014*\"jav\" + 0.011*\"developpeur web\" + 0.011*\"engine\" + 0.010*\"ingenieur\" + 0.008*\"developpeur jav\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_topics = 5\n",
    "lda, doc_term_matrixx = create_gensim_lda_model(\n",
    "    df['Title'], num_of_topics)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_transformedd = lda[doc_term_matrixx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_cs = matutils.corpus2csc(corpus_transformedd)\n",
    "all_topics_np = all_topics_cs.T.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lda1</th>\n",
       "      <th>lda2</th>\n",
       "      <th>lda3</th>\n",
       "      <th>lda4</th>\n",
       "      <th>lda5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.265784</td>\n",
       "      <td>0.197594</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>0.496304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050232</td>\n",
       "      <td>0.051122</td>\n",
       "      <td>0.797878</td>\n",
       "      <td>0.050767</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lda1      lda2      lda3      lda4      lda5\n",
       "0  0.265784  0.197594  0.020155  0.020164  0.496304\n",
       "1  0.050232  0.051122  0.797878  0.050767  0.050001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lda_Topic = pd.DataFrame(all_topics_np, index=df.index, columns=[\n",
    "                         'lda1', 'lda2', 'lda3', 'lda4', 'lda5'])\n",
    "\n",
    "Lda_Topic.head(2)\n",
    "# our brand new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Count</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Description</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>Dept</th>\n",
       "      <th>title_words</th>\n",
       "      <th>summary_words</th>\n",
       "      <th>contractWords</th>\n",
       "      <th>CDI</th>\n",
       "      <th>CDD</th>\n",
       "      <th>Freelance</th>\n",
       "      <th>Temps partiel</th>\n",
       "      <th>Temps plein</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>lat-long</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>lat*long</th>\n",
       "      <th>Regions</th>\n",
       "      <th>BagOfWords</th>\n",
       "      <th>lsa1</th>\n",
       "      <th>lsa2</th>\n",
       "      <th>lsa3</th>\n",
       "      <th>lsa4</th>\n",
       "      <th>lsa5</th>\n",
       "      <th>lda1</th>\n",
       "      <th>lda2</th>\n",
       "      <th>lda3</th>\n",
       "      <th>lda4</th>\n",
       "      <th>lda5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Developer – Expert sécurité</td>\n",
       "      <td>Arras</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Uptoo</td>\n",
       "      <td>4.5</td>\n",
       "      <td>32</td>\n",
       "      <td>Non renseigné</td>\n",
       "      <td>À PROPOS :Bienvenue dans notre PME spécialiste...</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>business developer expert sécurité</td>\n",
       "      <td>['propos', 'bienvenue', 'pme', 'spécialiste', ...</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(50.291048, 2.7772211)</td>\n",
       "      <td>50.291048</td>\n",
       "      <td>2.777221</td>\n",
       "      <td>139.669360</td>\n",
       "      <td>Île-de-France</td>\n",
       "      <td>business,develop,expert,secur,propos,bienvenu,...</td>\n",
       "      <td>0.046282</td>\n",
       "      <td>0.027923</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.019654</td>\n",
       "      <td>0.323825</td>\n",
       "      <td>0.265784</td>\n",
       "      <td>0.197594</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>0.496304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager Big Data H/F</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>Elitegroup Recruitment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Temps plein, CDI</td>\n",
       "      <td>Présentation de l'entreprise:Notre client est ...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>manager big data</td>\n",
       "      <td>['présentation', 'entreprise', 'client', 'cabi...</td>\n",
       "      <td>['temps', 'plein', 'cdi']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(48.8566969, 2.3514616)</td>\n",
       "      <td>48.856697</td>\n",
       "      <td>2.351462</td>\n",
       "      <td>114.884647</td>\n",
       "      <td>Île-de-France</td>\n",
       "      <td>manag,dat,present,entrepris,client,cabinet,con...</td>\n",
       "      <td>0.843184</td>\n",
       "      <td>-0.155558</td>\n",
       "      <td>0.341612</td>\n",
       "      <td>-0.091903</td>\n",
       "      <td>-0.182890</td>\n",
       "      <td>0.050232</td>\n",
       "      <td>0.051122</td>\n",
       "      <td>0.797878</td>\n",
       "      <td>0.050767</td>\n",
       "      <td>0.050001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title Location        Date                 Company  Rating  Count          Contract                                        Description  min_salary  max_salary  avg_salary  Dept                         title_words                                      summary_words              contractWords  CDI  CDD  Freelance  Temps partiel  Temps plein  Unknown                 lat-long        lat      long    lat*long        Regions                                         BagOfWords      lsa1      lsa2      lsa3      lsa4      lsa5      lda1      lda2      lda3      lda4      lda5\n",
       "0  Business Developer – Expert sécurité   Arras   2020-05-11                   Uptoo     4.5     32     Non renseigné  À PROPOS :Bienvenue dans notre PME spécialiste...     27000.0     55000.0     41000.0  62.0  business developer expert sécurité  ['propos', 'bienvenue', 'pme', 'spécialiste', ...                    ['nan']  0.0  0.0        0.0            0.0          0.0      1.0   (50.291048, 2.7772211)  50.291048  2.777221  139.669360  Île-de-France  business,develop,expert,secur,propos,bienvenu,...  0.046282  0.027923  0.079400  0.019654  0.323825  0.265784  0.197594  0.020155  0.020164  0.496304\n",
       "1                  Manager Big Data H/F   Paris   2020-04-29  Elitegroup Recruitment     3.0      0  Temps plein, CDI  Présentation de l'entreprise:Notre client est ...     55000.0     75000.0     65000.0  75.0                    manager big data  ['présentation', 'entreprise', 'client', 'cabi...  ['temps', 'plein', 'cdi']  1.0  0.0        0.0            0.0          1.0      0.0  (48.8566969, 2.3514616)  48.856697  2.351462  114.884647  Île-de-France  manag,dat,present,entrepris,client,cabinet,con...  0.843184 -0.155558  0.341612 -0.091903 -0.182890  0.050232  0.051122  0.797878  0.050767  0.050001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, Lsa_Topic, Lda_Topic], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF \n",
    "\n",
    "For NMF, we need to obtain a design matrix. To improve results, I am going to apply TfIdf transformation to the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF  # unsupervised to find topics\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95,\n",
    "                                   min_df=0.05, tokenizer=parse_text, strip_accents='ascii')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['Description'])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "nmf = NMF(n_components=5, random_state=11,\n",
    "              alpha=.1, l1_ratio=.5, init='nndsvd')\n",
    "\n",
    "# Weights for documents relative to topics\n",
    "W = nmf.fit_transform(tfidf)\n",
    "# term weights : Weights for terms relative to topics\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = pd.DataFrame(W, columns=['nmf1','nmf2','nmf3','nmf4','nmf5'])\n",
    "df = pd.concat([df, W], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777, 42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan = df[df['avg_salary'].isna()]\n",
    "df_salary = df[~df.isin(df_nan)].dropna(how='all')\n",
    "df_salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.to_csv('ML_RDY_SALARY.csv', index=False)\n",
    "df_nan.to_csv('ML_RDY_SALARY.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
